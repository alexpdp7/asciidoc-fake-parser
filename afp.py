import json
import pathlib
import re
import sys
import subprocess

import bs4


"""
This module implements an asciidoc_fake_parse function that uses AsciiDoctor to
convert AsciiDoc to HTML, then correlates positions in the original AsciiDoc
file to the parsed HTML.

The result is something similar to an annotated AST and can be used to do
structural processing of AsciiDoc.
"""


def adoc_to_soup(path):
    return bs4.BeautifulSoup(subprocess.run(["asciidoctor", "-b", "html5", "-a", "experimental", "-e", path, "-o", "-"], check=True, stdout=subprocess.PIPE).stdout, features="html.parser")


def walk(soup):
    yield soup
    if isinstance(soup, bs4.NavigableString):
        return
    for elem in soup.children:
        yield from walk(elem)


def elem_to_path(elem):
    return "/".join([p.name for p in elem.parents])


def asciidoc_fake_parse(path: pathlib.Path):
    text = path.read_text()
    soup = adoc_to_soup(path)
    pos = 0
    blocks = []
    for elem in walk(soup):
        if not isinstance(elem, bs4.NavigableString) or not elem.text.strip():
            continue

        # Some text elements are generated by AsciiDoctor, and don't correspond to content in the original AsciiDoc file
        elem_text = elem.text

        # skip admonitions
        def is_admonition_text(kind):
            return elem_text == kind and elem.parent.parent.parent.parent.parent.attrs["class"][0:2] == ['admonitionblock', kind.lower()]
        if is_admonition_text("Note") or is_admonition_text("Important"):
            continue
        # skip callouts
        if re.match(r"\(\d+\)", elem_text) and elem.parent.attrs.get("class") == ["conum"]:
            continue
        # skip Figure x. text in captions
        if elem_text.startswith("Figure") and elem.parent.parent.attrs["class"] == ['imageblock', 'text-center'] and elem.parent.attrs["class"] == ["title"]:
            elem_text = re.sub(r"^Figure \d+\. ", "", elem_text)
        # skip Table x. text in captions
        if elem_text.startswith("Table") and elem.parent.name == "caption":
            elem_text = re.sub(r"^Table \d+\. ", "", elem_text)
        # menu:[] separator
        if elem_text == "›":
            continue
        # hack: skip code blocks to prevent annoying issues with escapes inside
        if elem.find_parent("pre"):
            continue
        # ignore xrefs
        if re.match(r"\[[^ ]+\]", elem_text) and elem.parent.name == "a":
            continue

        # Once extraneous text elements are skipped, we work word by word on the parsed HTML
        # We do this because line comments are not present in the HTML output
        for i, line in enumerate(elem_text.split()):
            original = line.replace("\xa0", "{nbsp}").replace("’", "'").replace("…\u200b", "...")
            elem_position_in_text = text.find(original, pos)
            assert elem_position_in_text != -1, f"can't find {repr(original)} after {pos}"
            if i == 0:
                blocks.append({"text": text[pos:elem_position_in_text], "path": None, "start": pos})
            blocks.append({"text": original, "path": elem_to_path(elem), "start": elem_position_in_text})
            pos = elem_position_in_text + len(original)
    return blocks


def main():
    print(json.dumps(asciidoc_fake_parse(pathlib.Path(sys.argv[1]))))


if __name__ == "__main__":
    main()
