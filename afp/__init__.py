import json
import pathlib
import re
import sys
import subprocess

import bs4


"""
This module implements an asciidoc_fake_parse function that uses AsciiDoctor to
convert AsciiDoc to HTML, then correlates positions in the original AsciiDoc
file to the parsed HTML.

The result is something similar to an annotated AST and can be used to do
structural processing of AsciiDoc.
"""


def adoc_to_soup(path, silence_asciidoctor=False):
    return bs4.BeautifulSoup(subprocess.run(["asciidoctor", "-b", "html5", "-a", "experimental", "-e", path, "-o", "-"],
                                            check=True,
                                            stdout=subprocess.PIPE,
                                            stderr=subprocess.DEVNULL if silence_asciidoctor else None,
                                            ).stdout, features="html.parser")


def walk(soup):
    yield soup
    if isinstance(soup, bs4.NavigableString):
        return
    for elem in soup.children:
        yield from walk(elem)


def elem_to_path(elem):
    return "/".join([p.name for p in elem.parents])


def consolidate(blocks, text):
    """
    Joins blocks with the same path with only whitespace in between
    """
    result = []

    i = 0
    while i < len(blocks):
        consolidated_block = blocks[i]
        j = i + 1
        while j < len(blocks):
            candidate_block = blocks[j]
            if not consolidated_block["path"] == candidate_block["path"]:
                break
            pos_of_end_of_consolidated_block_text = consolidated_block["start"] + len(consolidated_block["text"])
            gap = text[pos_of_end_of_consolidated_block_text:candidate_block["start"]]
            if gap.strip() != "":
                break
            consolidated_block["text"] += gap + candidate_block["text"]
            j = j + 1
        result.append(consolidated_block)
        i = j
    return result


def asciidoc_fake_parse(path: pathlib.Path, silence_asciidoctor=False):
    text = path.read_text()
    soup = adoc_to_soup(path, silence_asciidoctor)
    pos = 0
    blocks = []
    for elem in walk(soup):
        if not isinstance(elem, bs4.NavigableString) or not elem.text.strip():
            continue

        # Some text elements are generated by AsciiDoctor, and don't correspond to content in the original AsciiDoc file
        elem_text = elem.text

        # skip admonitions
        def is_admonition_text(kind):
            return elem_text == kind and elem.parent.parent.parent.parent.parent.attrs["class"][0:2] == ['admonitionblock', kind.lower()]
        if is_admonition_text("Note") or is_admonition_text("Important") or is_admonition_text("Warning"):
            continue
        # skip callouts
        if re.match(r"\(\d+\)", elem_text) and elem.parent.attrs.get("class") == ["conum"]:
            continue
        # skip Figure x. text in captions
        if elem_text.startswith("Figure") and elem.parent.parent.attrs["class"][0:2] == ['imageblock', 'text-center'] and elem.parent.attrs["class"] == ["title"]:
            elem_text = re.sub(r"^Figure \d+\. ", "", elem_text)
        # skip Table x. text in captions
        if elem_text.startswith("Table") and elem.parent.name == "caption":
            elem_text = re.sub(r"^Table \d+\. ", "", elem_text)
        # menu:[] separator
        if elem_text == "›":
            continue
        # hack: skip code blocks to prevent annoying issues with escapes inside
        if elem.find_parent("pre"):
            continue
        # ignore xrefs
        if re.match(r"\[[^ ]+\]", elem_text) and elem.parent.name == "a":
            continue
        # ignore processing errors
        if elem_text.startswith("Unresolved directive in "):
            continue

        # Once extraneous text elements are skipped, we work word by word on the parsed HTML
        # We do this because line comments are not present in the HTML output
        for i, line in enumerate(elem_text.split()):
            original = line.replace("\xa0", "{nbsp}").replace("’", "'").replace("…\u200b", "...")
            elem_position_in_text = text.find(original, pos)
            if elem_position_in_text == -1:
                # that didn't work. now try ignoring backslashes...
                elem_position_in_text = (text[pos:].replace("\\", "")).find(original)
                if elem_position_in_text != -1:
                    elem_position_in_text += pos
            assert elem_position_in_text != -1, f"can't find {repr(original)} after {pos}"
            if i == 0:
                blocks.append({"text": text[pos:elem_position_in_text], "path": None, "start": pos})
            blocks.append({"text": original, "path": elem_to_path(elem), "start": elem_position_in_text})
            pos = elem_position_in_text + len(original)

    blocks = consolidate(blocks, text)
    return blocks


def main():
    print(json.dumps(asciidoc_fake_parse(pathlib.Path(sys.argv[1]))))


if __name__ == "__main__":
    main()
